{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入相关的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TripletMarginLoss\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部署模型，修改分类层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用预训练参数\n",
    "from SqueezeNet.models.SqueezeNet import SqueezeNet\n",
    "\n",
    "model = SqueezeNet(version=\"1_1\")\n",
    "model.load_state_dict(torch.load('squeezenet1_1_weights.pth'))\n",
    "\n",
    "\n",
    "# 冻结参数层\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 修改最后一层\n",
    "\n",
    "print(model.classifier[1])\n",
    "final_conv = nn.Conv2d(512, 256, kernel_size=1)\n",
    "init.normal_(final_conv.weight, mean=0.0, std=0.01)\n",
    "init.constant_(final_conv.bias, 0.0)\n",
    "model.classifier[1] = final_conv\n",
    "\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "\n",
    "for params in model.classifier[1].parameters():\n",
    "    params.requires_grad = True\n",
    "    \n",
    "# 解冻模型的最后1个Fire模块\n",
    "for param in model.features[-1:].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "    \n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img_001_0 = Image.open('./facenet/data_cropped/001/001_0.bmp')\n",
    "# test_img_001_1 = Image.open('./facenet/data_cropped/001/001_1.bmp')\n",
    "# test_img_001_2 = Image.open('./facenet/data_cropped/001/001_2.bmp')\n",
    "# test_img_003_3 = Image.open('./facenet/data_cropped/003/003_3.bmp')\n",
    "# test_img_007_3 = Image.open('./facenet/data_cropped/007/007_3.bmp')\n",
    "# test_img_003_1 = Image.open('./facenet/data_cropped/003/003_1.bmp')\n",
    "# test_img_003_2 = Image.open('./facenet/data_cropped/003/003_2.bmp')\n",
    "\n",
    "# lables = [\"001_0\", \"001_1\", \"001_2\", \"003_3\", \"007_3\", \"003_1\", \"003_2\"]\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#             transforms.Resize((224, 224)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "#                                  0.229, 0.224, 0.225])\n",
    "#         ])\n",
    "\n",
    "# aligned = []\n",
    "# aligned.append(transform(test_img_001_0))\n",
    "# aligned.append(transform(test_img_001_1))\n",
    "# aligned.append(transform(test_img_001_2))\n",
    "# aligned.append(transform(test_img_003_3))\n",
    "# aligned.append(transform(test_img_007_3))\n",
    "# aligned.append(transform(test_img_003_1))\n",
    "# aligned.append(transform(test_img_003_2))\n",
    "\n",
    "# model.eval()\n",
    "# aligned = torch.stack(aligned).to('cuda')\n",
    "# emdeddings = model(aligned).cpu().detach()\n",
    "\n",
    "# dists = [[(e1 - e2).norm().item() for e2 in emdeddings] for e1 in emdeddings]\n",
    "# pd.DataFrame(dists, columns=lables, index=lables)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取并且定制数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = TripletMarginLoss(margin=0.2, p=2)\n",
    "\n",
    "\n",
    "# 分割三元组数据集\n",
    "class TripletFaceDataset(Dataset):\n",
    "    def __init__(self, image_folder):\n",
    "        self.image_folder = image_folder\n",
    "        self.persons = os.listdir(image_folder)\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        anchor_person = random.choice(self.persons)\n",
    "        positive_person = anchor_person\n",
    "        negative_person = random.choice(self.persons)\n",
    "        while negative_person == anchor_person:\n",
    "            negative_person = random.choice(self.persons)\n",
    "\n",
    "        anchor_img_path = random.choice(os.listdir(\n",
    "            os.path.join(self.image_folder, anchor_person)))\n",
    "        positive_img_path = random.choice(os.listdir(\n",
    "            os.path.join(self.image_folder, positive_person)))\n",
    "        negative_img_path = random.choice(os.listdir(\n",
    "            os.path.join(self.image_folder, negative_person)))\n",
    "\n",
    "        anchor_img = Image.open(os.path.join(\n",
    "            self.image_folder, anchor_person, anchor_img_path))\n",
    "        positive_img = Image.open(os.path.join(\n",
    "            self.image_folder, anchor_person, positive_img_path))\n",
    "        negative_img = Image.open(os.path.join(\n",
    "            self.image_folder, positive_person, negative_img_path))\n",
    "\n",
    "        # 进行数据处理\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                                 0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        anchor_img = transform(anchor_img)\n",
    "        positive_img = transform(positive_img)\n",
    "        negative_img = transform(negative_img)\n",
    "\n",
    "        return anchor_img, positive_img, negative_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.persons) * 5  # 假设每个人有5张图片\n",
    "\n",
    "labels = os.listdir('./facenet/data_cropped')\n",
    "# print(labels)\n",
    "\n",
    "# 切割数据集八二分\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 800\n",
    "workers = 0 if os.name == 'nt' else 8\n",
    "\n",
    "transforming = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                                 0.229, 0.224, 0.225])\n",
    "        ])\n",
    "dataset = datasets.ImageFolder('./facenet/data_cropped', transform=transforming)\n",
    "\n",
    "img_inds = np.arange(len(labels))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
    "valid_inds = img_inds[int(0.8 * len(img_inds)):]\n",
    "\n",
    "train_loaders = DataLoader(\n",
    "    dataset, batch_size = batch_size, sampler = train_inds)\n",
    "\n",
    "valid_loaders = DataLoader(\n",
    "    dataset, batch_size = batch_size, sampler = valid_inds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定制优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "squeezenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
