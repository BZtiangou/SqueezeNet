{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入相关的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import LambdaLR,ReduceLROnPlateau\n",
    "from torchvision import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TripletMarginLoss\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import torch.nn.init as init\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部署模型，修改分类层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (6): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 使用预训练参数\n",
    "from models.SqueezeNet import SqueezeNet\n",
    "\n",
    "model = SqueezeNet(version=\"1_1\")\n",
    "model.load_state_dict(torch.load('squeezenet1_1_weights.pth'))\n",
    "\n",
    "\n",
    "# 冻结参数层\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 修改最后一层\n",
    "\n",
    "print(model.classifier[1])\n",
    "final_conv = nn.Conv2d(512, 128, kernel_size=1)\n",
    "init.normal_(final_conv.weight, mean=0.0, std=0.01)\n",
    "init.constant_(final_conv.bias, 0.0)\n",
    "model.classifier[1] = final_conv\n",
    "\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "\n",
    "for params in model.classifier[1].parameters():\n",
    "    params.requires_grad = True\n",
    "    \n",
    "# 解冻模型的最后1个Fire模块\n",
    "for param in model.features[-1:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img_001_0 = Image.open('./data_cropped/001/001_0.bmp')\n",
    "# test_img_001_1 = Image.open('./data_cropped/001/001_1.bmp')\n",
    "# test_img_001_2 = Image.open('./data_cropped/001/001_2.bmp')\n",
    "# test_img_003_3 = Image.open('./data_cropped/003/003_3.bmp')\n",
    "# test_img_007_3 = Image.open('./data_cropped/007/007_3.bmp')\n",
    "# test_img_003_1 = Image.open('./data_cropped/003/003_1.bmp')\n",
    "# test_img_003_2 = Image.open('./data_cropped/003/003_2.bmp')\n",
    "\n",
    "# lables = [\"001_0\", \"001_1\", \"001_2\", \"003_3\", \"007_3\", \"003_1\", \"003_2\"]\n",
    "\n",
    "transforming = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    # 数据增强\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转，有助于人脸识别任务\n",
    "    transforms.RandomRotation(10),  # 随机旋转，-10到10度之间\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # 随机调整亮度、对比度和饱和度\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),  # 随机仿射变换\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                                 0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# aligned = []\n",
    "# aligned.append(transforming(test_img_001_0))\n",
    "# aligned.append(transforming(test_img_001_1))\n",
    "# aligned.append(transforming(test_img_001_2))\n",
    "# aligned.append(transforming(test_img_003_3))\n",
    "# aligned.append(transforming(test_img_007_3))\n",
    "# aligned.append(transforming(test_img_003_1))\n",
    "# aligned.append(transforming(test_img_003_2))\n",
    "\n",
    "# model.eval()\n",
    "# aligned = torch.stack(aligned).to('cuda')\n",
    "# emdeddings = model(aligned).cpu().detach()\n",
    " \n",
    "# print(emdeddings[0].shape)\n",
    "# dists = [[(e1 - e2).norm().item() for e2 in emdeddings] for e1 in emdeddings]\n",
    "# pd.DataFrame(dists, columns=lables, index=lables)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取并且定制数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = TripletMarginLoss(margin=0.2, p=2)\n",
    "\n",
    "\n",
    "# 分割三元组数据集\n",
    "class TripletFaceDataset(Dataset):\n",
    "    def __init__(self, image_folder,persons,transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.persons = persons\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        anchor_person = random.choice(self.persons)\n",
    "        positive_person = anchor_person\n",
    "        negative_person = random.choice(self.persons)\n",
    "        while negative_person == anchor_person:\n",
    "            negative_person = random.choice(self.persons)\n",
    "\n",
    "        anchor_img_path = random.choice(os.listdir(\n",
    "            os.path.join(self.image_folder, anchor_person)))\n",
    "        positive_img_path = random.choice(os.listdir(\n",
    "            os.path.join(self.image_folder, positive_person)))\n",
    "        negative_img_path = random.choice(os.listdir(\n",
    "            os.path.join(self.image_folder, negative_person)))\n",
    "\n",
    "        anchor_img = Image.open(os.path.join(\n",
    "            self.image_folder, anchor_person, anchor_img_path))\n",
    "        positive_img = Image.open(os.path.join(\n",
    "            self.image_folder, positive_person, positive_img_path))\n",
    "        negative_img = Image.open(os.path.join(\n",
    "            self.image_folder, negative_person, negative_img_path))\n",
    "\n",
    "        # 进行数据处理\n",
    "        transform = self.transform\n",
    "\n",
    "        anchor_img = transform(anchor_img)\n",
    "        positive_img = transform(positive_img)\n",
    "        negative_img = transform(negative_img)\n",
    "\n",
    "        return (anchor_img, positive_img, negative_img),(anchor_person, positive_person, negative_person)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.persons) * 5  # 假设每个人有5张图片\n",
    "\n",
    "\n",
    "# print(labels)\n",
    "\n",
    "# 切割数据集八二分\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 300\n",
    "workers = 0 if os.name == 'nt' else 8\n",
    "\n",
    "\n",
    "dataset = datasets.ImageFolder('./data_cropped', transform=transforming)\n",
    "labels = os.listdir('./data_cropped')\n",
    "# print(labels)\n",
    "random.shuffle(labels)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = TripletFaceDataset(\n",
    "    image_folder='./data_cropped', persons=train_idx, transform=transforming\n",
    "    )\n",
    "\n",
    "test_dataset = TripletFaceDataset(\n",
    "    image_folder='./data_cropped', persons=test_idx, transform=transforming\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定制优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# def lambda_rule(epoch,max_epoch):\n",
    "#     max_epoch = 20\n",
    "#     return (1-epoch/max_epoch)**0.9 ##多项式衰减\n",
    "\n",
    "# scheduler = LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10)\n",
    "\n",
    "\n",
    "# 定制参考嵌入向量\n",
    "reference_embeddings = []\n",
    "reference_labels = []\n",
    "model.eval()\n",
    "# 遍历数据集每个文件夹，每个文件夹embeddings计算平均值，放进reference_embeddings,对应的标签放进reference_labels\n",
    "for label in labels:\n",
    "    img_path = os.listdir(os.path.join('./data_cropped', label))\n",
    "    if img_path:\n",
    "        first_img = img_path[0]\n",
    "        img = Image.open(os.path.join('./data_cropped', label, first_img))\n",
    "        img = transforming(img).unsqueeze(0).to('cuda')\n",
    "        with torch.no_grad():\n",
    "            embedding = model(img).cpu().detach().numpy()\n",
    "            temsor_embedding = torch.from_numpy(embedding).to('cuda')\n",
    "            \n",
    "        reference_embeddings.append(temsor_embedding)\n",
    "        reference_labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "----------\n",
      "\n",
      "循环 1/300\n",
      "----------\n",
      "Epoch0 average loss:0.01304140075808391\n",
      "Epoch0 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.354\n",
      "correct: 177\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 2/300\n",
      "----------\n",
      "Epoch1 average loss:0.01210033247480169\n",
      "Epoch1 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.354\n",
      "correct: 177\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 3/300\n",
      "----------\n",
      "Epoch2 average loss:0.012980028754100204\n",
      "Epoch2 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.366\n",
      "correct: 183\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 4/300\n",
      "----------\n",
      "Epoch3 average loss:0.01647980703273788\n",
      "Epoch3 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.34\n",
      "correct: 170\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 5/300\n",
      "----------\n",
      "Epoch4 average loss:0.015369828324764967\n",
      "Epoch4 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.414\n",
      "correct: 207\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 6/300\n",
      "----------\n",
      "Epoch5 average loss:0.015280023566447198\n",
      "Epoch5 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.362\n",
      "correct: 181\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 7/300\n",
      "----------\n",
      "Epoch6 average loss:0.01525284763192758\n",
      "Epoch6 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.378\n",
      "correct: 189\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 8/300\n",
      "----------\n",
      "Epoch7 average loss:0.013227857649326324\n",
      "Epoch7 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.346\n",
      "correct: 173\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 9/300\n",
      "----------\n",
      "Epoch8 average loss:0.01204817573307082\n",
      "Epoch8 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.398\n",
      "correct: 199\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 10/300\n",
      "----------\n",
      "Epoch9 average loss:0.014706259942613542\n",
      "Epoch9 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.36\n",
      "correct: 180\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 11/300\n",
      "----------\n",
      "Epoch10 average loss:0.016369916789699346\n",
      "Epoch10 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.36\n",
      "correct: 180\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 12/300\n",
      "----------\n",
      "Epoch11 average loss:0.014835975773166865\n",
      "Epoch11 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.418\n",
      "correct: 209\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 13/300\n",
      "----------\n",
      "Epoch12 average loss:0.014193589333444834\n",
      "Epoch12 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.426\n",
      "correct: 213\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 14/300\n",
      "----------\n",
      "Epoch13 average loss:0.013986227277200669\n",
      "Epoch13 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.354\n",
      "correct: 177\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 15/300\n",
      "----------\n",
      "Epoch14 average loss:0.012926818279083818\n",
      "Epoch14 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.364\n",
      "correct: 182\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 16/300\n",
      "----------\n",
      "Epoch15 average loss:0.015507324947975576\n",
      "Epoch15 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.34\n",
      "correct: 170\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 17/300\n",
      "----------\n",
      "Epoch16 average loss:0.01891464221989736\n",
      "Epoch16 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.372\n",
      "correct: 186\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 18/300\n",
      "----------\n",
      "Epoch17 average loss:0.015913595867459662\n",
      "Epoch17 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.346\n",
      "correct: 173\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 19/300\n",
      "----------\n",
      "Epoch18 average loss:0.013327457592822611\n",
      "Epoch18 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.36\n",
      "correct: 180\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 20/300\n",
      "----------\n",
      "Epoch19 average loss:0.018709855678025633\n",
      "Epoch19 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.36\n",
      "correct: 180\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 21/300\n",
      "----------\n",
      "Epoch20 average loss:0.01743238855851814\n",
      "Epoch20 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.368\n",
      "correct: 184\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 22/300\n",
      "----------\n",
      "Epoch21 average loss:0.01588269745116122\n",
      "Epoch21 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.356\n",
      "correct: 178\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 23/300\n",
      "----------\n",
      "Epoch22 average loss:0.011818213621154428\n",
      "Epoch22 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.384\n",
      "correct: 192\n",
      "Current learning rate:  [1e-05]\n",
      "\n",
      "循环 24/300\n",
      "----------\n",
      "Epoch23 average loss:0.02048589033074677\n",
      "Epoch23 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.372\n",
      "correct: 186\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 25/300\n",
      "----------\n",
      "Epoch24 average loss:0.01778123341500759\n",
      "Epoch24 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.408\n",
      "correct: 204\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 26/300\n",
      "----------\n",
      "Epoch25 average loss:0.013749959180131555\n",
      "Epoch25 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.376\n",
      "correct: 188\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 27/300\n",
      "----------\n",
      "Epoch26 average loss:0.017024138884153217\n",
      "Epoch26 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.348\n",
      "correct: 174\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 28/300\n",
      "----------\n",
      "Epoch27 average loss:0.011628284235484898\n",
      "Epoch27 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.394\n",
      "correct: 197\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 29/300\n",
      "----------\n",
      "Epoch28 average loss:0.015249945397954434\n",
      "Epoch28 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.37\n",
      "correct: 185\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 30/300\n",
      "----------\n",
      "Epoch29 average loss:0.015969828818924725\n",
      "Epoch29 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.398\n",
      "correct: 199\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 31/300\n",
      "----------\n",
      "Epoch30 average loss:0.013641032797750086\n",
      "Epoch30 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.36\n",
      "correct: 180\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 32/300\n",
      "----------\n",
      "Epoch31 average loss:0.016481274156831205\n",
      "Epoch31 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.366\n",
      "correct: 183\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 33/300\n",
      "----------\n",
      "Epoch32 average loss:0.014857017260510474\n",
      "Epoch32 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.386\n",
      "correct: 193\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 34/300\n",
      "----------\n",
      "Epoch33 average loss:0.01583034236682579\n",
      "Epoch33 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.37\n",
      "correct: 185\n",
      "Current learning rate:  [5e-06]\n",
      "\n",
      "循环 35/300\n",
      "----------\n",
      "Epoch34 average loss:0.013131930551026016\n",
      "Epoch34 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.388\n",
      "correct: 194\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 36/300\n",
      "----------\n",
      "Epoch35 average loss:0.01657827926101163\n",
      "Epoch35 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.378\n",
      "correct: 189\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 37/300\n",
      "----------\n",
      "Epoch36 average loss:0.017658952274359763\n",
      "Epoch36 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.388\n",
      "correct: 194\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 38/300\n",
      "----------\n",
      "Epoch37 average loss:0.015426614816533402\n",
      "Epoch37 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.392\n",
      "correct: 196\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 39/300\n",
      "----------\n",
      "Epoch38 average loss:0.017872851458378136\n",
      "Epoch38 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.364\n",
      "correct: 182\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 40/300\n",
      "----------\n",
      "Epoch39 average loss:0.013155471242498606\n",
      "Epoch39 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.394\n",
      "correct: 197\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 41/300\n",
      "----------\n",
      "Epoch40 average loss:0.013337398006115109\n",
      "Epoch40 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.352\n",
      "correct: 176\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 42/300\n",
      "----------\n",
      "Epoch41 average loss:0.015612340066581964\n",
      "Epoch41 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.374\n",
      "correct: 187\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 43/300\n",
      "----------\n",
      "Epoch42 average loss:0.019448479171842337\n",
      "Epoch42 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.374\n",
      "correct: 187\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 44/300\n",
      "----------\n",
      "Epoch43 average loss:0.017371281457599252\n",
      "Epoch43 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.382\n",
      "correct: 191\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 45/300\n",
      "----------\n",
      "Epoch44 average loss:0.01567666605114937\n",
      "Epoch44 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.394\n",
      "correct: 197\n",
      "Current learning rate:  [2.5e-06]\n",
      "\n",
      "循环 46/300\n",
      "----------\n",
      "Epoch45 average loss:0.016522498637641547\n",
      "Epoch45 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.396\n",
      "correct: 198\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 47/300\n",
      "----------\n",
      "Epoch46 average loss:0.015290386567357928\n",
      "Epoch46 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.36\n",
      "correct: 180\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 48/300\n",
      "----------\n",
      "Epoch47 average loss:0.013875035307137296\n",
      "Epoch47 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.362\n",
      "correct: 181\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 49/300\n",
      "----------\n",
      "Epoch48 average loss:0.01353983814624371\n",
      "Epoch48 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.37\n",
      "correct: 185\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 50/300\n",
      "----------\n",
      "Epoch49 average loss:0.015115106711164117\n",
      "Epoch49 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.336\n",
      "correct: 168\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 51/300\n",
      "----------\n",
      "Epoch50 average loss:0.014002263958900585\n",
      "Epoch50 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.372\n",
      "correct: 186\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 52/300\n",
      "----------\n",
      "Epoch51 average loss:0.016695459256879985\n",
      "Epoch51 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.364\n",
      "correct: 182\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 53/300\n",
      "----------\n",
      "Epoch52 average loss:0.02085001621162519\n",
      "Epoch52 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.374\n",
      "correct: 187\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 54/300\n",
      "----------\n",
      "Epoch53 average loss:0.011987108853645623\n",
      "Epoch53 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.358\n",
      "correct: 179\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 55/300\n",
      "----------\n",
      "Epoch54 average loss:0.01545332808746025\n",
      "Epoch54 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.354\n",
      "correct: 177\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 56/300\n",
      "----------\n",
      "Epoch55 average loss:0.015473874344024807\n",
      "Epoch55 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.41\n",
      "correct: 205\n",
      "Current learning rate:  [1.25e-06]\n",
      "\n",
      "循环 57/300\n",
      "----------\n",
      "Epoch56 average loss:0.011824377870652825\n",
      "Epoch56 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.338\n",
      "correct: 169\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 58/300\n",
      "----------\n",
      "Epoch57 average loss:0.014928672695532441\n",
      "Epoch57 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.384\n",
      "correct: 192\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 59/300\n",
      "----------\n",
      "Epoch58 average loss:0.01487366808578372\n",
      "Epoch58 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.342\n",
      "correct: 171\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 60/300\n",
      "----------\n",
      "Epoch59 average loss:0.013874578100512736\n",
      "Epoch59 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.366\n",
      "correct: 183\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 61/300\n",
      "----------\n",
      "Epoch60 average loss:0.015757175744511187\n",
      "Epoch60 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.378\n",
      "correct: 189\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 62/300\n",
      "----------\n",
      "Epoch61 average loss:0.01627538149477914\n",
      "Epoch61 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.386\n",
      "correct: 193\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 63/300\n",
      "----------\n",
      "Epoch62 average loss:0.016584884375333786\n",
      "Epoch62 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.386\n",
      "correct: 193\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 64/300\n",
      "----------\n",
      "Epoch63 average loss:0.0147409078781493\n",
      "Epoch63 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.386\n",
      "correct: 193\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 65/300\n",
      "----------\n",
      "Epoch64 average loss:0.01633450001827441\n",
      "Epoch64 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.372\n",
      "correct: 186\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 66/300\n",
      "----------\n",
      "Epoch65 average loss:0.01750806230120361\n",
      "Epoch65 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.398\n",
      "correct: 199\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 67/300\n",
      "----------\n",
      "Epoch66 average loss:0.01609255518997088\n",
      "Epoch66 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.388\n",
      "correct: 194\n",
      "Current learning rate:  [6.25e-07]\n",
      "\n",
      "循环 68/300\n",
      "----------\n",
      "Epoch67 average loss:0.019020937383174896\n",
      "Epoch67 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.368\n",
      "correct: 184\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 69/300\n",
      "----------\n",
      "Epoch68 average loss:0.014184393978212029\n",
      "Epoch68 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.374\n",
      "correct: 187\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 70/300\n",
      "----------\n",
      "Epoch69 average loss:0.0168791072210297\n",
      "Epoch69 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.346\n",
      "correct: 173\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 71/300\n",
      "----------\n",
      "Epoch70 average loss:0.01726722257444635\n",
      "Epoch70 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.362\n",
      "correct: 181\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 72/300\n",
      "----------\n",
      "Epoch71 average loss:0.01619340683100745\n",
      "Epoch71 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.388\n",
      "correct: 194\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 73/300\n",
      "----------\n",
      "Epoch72 average loss:0.014656611368991435\n",
      "Epoch72 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.382\n",
      "correct: 191\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 74/300\n",
      "----------\n",
      "Epoch73 average loss:0.013545130932470784\n",
      "Epoch73 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.334\n",
      "correct: 167\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 75/300\n",
      "----------\n",
      "Epoch74 average loss:0.016378147818613797\n",
      "Epoch74 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.396\n",
      "correct: 198\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 76/300\n",
      "----------\n",
      "Epoch75 average loss:0.012772932648658752\n",
      "Epoch75 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.35\n",
      "correct: 175\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 77/300\n",
      "----------\n",
      "Epoch76 average loss:0.014300522743724287\n",
      "Epoch76 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.39\n",
      "correct: 195\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 78/300\n",
      "----------\n",
      "Epoch77 average loss:0.013913442147895694\n",
      "Epoch77 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.378\n",
      "correct: 189\n",
      "Current learning rate:  [3.125e-07]\n",
      "\n",
      "循环 79/300\n",
      "----------\n",
      "Epoch78 average loss:0.015125825593713671\n",
      "Epoch78 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.346\n",
      "correct: 173\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 80/300\n",
      "----------\n",
      "Epoch79 average loss:0.014580984832718968\n",
      "Epoch79 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.348\n",
      "correct: 174\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 81/300\n",
      "----------\n",
      "Epoch80 average loss:0.017024305183440447\n",
      "Epoch80 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.318\n",
      "correct: 159\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 82/300\n",
      "----------\n",
      "Epoch81 average loss:0.017855109530501068\n",
      "Epoch81 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.342\n",
      "correct: 171\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 83/300\n",
      "----------\n",
      "Epoch82 average loss:0.0179891143925488\n",
      "Epoch82 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.38\n",
      "correct: 190\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 84/300\n",
      "----------\n",
      "Epoch83 average loss:0.014065556810237467\n",
      "Epoch83 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.38\n",
      "correct: 190\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 85/300\n",
      "----------\n",
      "Epoch84 average loss:0.016168902329809498\n",
      "Epoch84 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.398\n",
      "correct: 199\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 86/300\n",
      "----------\n",
      "Epoch85 average loss:0.016576269699726254\n",
      "Epoch85 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.382\n",
      "correct: 191\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 87/300\n",
      "----------\n",
      "Epoch86 average loss:0.012755369127262384\n",
      "Epoch86 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.384\n",
      "correct: 192\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 88/300\n",
      "----------\n",
      "Epoch87 average loss:0.013949957035947591\n",
      "Epoch87 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.37\n",
      "correct: 185\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 89/300\n",
      "----------\n",
      "Epoch88 average loss:0.016445871093310416\n",
      "Epoch88 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.372\n",
      "correct: 186\n",
      "Current learning rate:  [1.5625e-07]\n",
      "\n",
      "循环 90/300\n",
      "----------\n",
      "Epoch89 average loss:0.019838551816064864\n",
      "Epoch89 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.346\n",
      "correct: 173\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 91/300\n",
      "----------\n",
      "Epoch90 average loss:0.01577687515236903\n",
      "Epoch90 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.378\n",
      "correct: 189\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 92/300\n",
      "----------\n",
      "Epoch91 average loss:0.017198407498653978\n",
      "Epoch91 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.384\n",
      "correct: 192\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 93/300\n",
      "----------\n",
      "Epoch92 average loss:0.012370920623652637\n",
      "Epoch92 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.392\n",
      "correct: 196\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 94/300\n",
      "----------\n",
      "Epoch93 average loss:0.015225023671519011\n",
      "Epoch93 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.364\n",
      "correct: 182\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 95/300\n",
      "----------\n",
      "Epoch94 average loss:0.01659427850972861\n",
      "Epoch94 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.392\n",
      "correct: 196\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 96/300\n",
      "----------\n",
      "Epoch95 average loss:0.014063358132261783\n",
      "Epoch95 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.356\n",
      "correct: 178\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 97/300\n",
      "----------\n",
      "Epoch96 average loss:0.014963803871069103\n",
      "Epoch96 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.398\n",
      "correct: 199\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 98/300\n",
      "----------\n",
      "Epoch97 average loss:0.014654715836513788\n",
      "Epoch97 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.346\n",
      "correct: 173\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 99/300\n",
      "----------\n",
      "Epoch98 average loss:0.017122032993938774\n",
      "Epoch98 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.412\n",
      "correct: 206\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 100/300\n",
      "----------\n",
      "Epoch99 average loss:0.012667188071645796\n",
      "Epoch99 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.382\n",
      "correct: 191\n",
      "Current learning rate:  [7.8125e-08]\n",
      "\n",
      "循环 101/300\n",
      "----------\n",
      "Epoch100 average loss:0.01640853233402595\n",
      "Epoch100 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.416\n",
      "correct: 208\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 102/300\n",
      "----------\n",
      "Epoch101 average loss:0.015116563707124442\n",
      "Epoch101 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.336\n",
      "correct: 168\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 103/300\n",
      "----------\n",
      "Epoch102 average loss:0.017238603701116517\n",
      "Epoch102 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.394\n",
      "correct: 197\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 104/300\n",
      "----------\n",
      "Epoch103 average loss:0.017209194076713175\n",
      "Epoch103 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.358\n",
      "correct: 179\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 105/300\n",
      "----------\n",
      "Epoch104 average loss:0.014347905816975981\n",
      "Epoch104 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.346\n",
      "correct: 173\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 106/300\n",
      "----------\n",
      "Epoch105 average loss:0.013323373510502279\n",
      "Epoch105 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.358\n",
      "correct: 179\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 107/300\n",
      "----------\n",
      "Epoch106 average loss:0.01728804298909381\n",
      "Epoch106 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.386\n",
      "correct: 193\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 108/300\n",
      "----------\n",
      "Epoch107 average loss:0.015118338982574642\n",
      "Epoch107 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.36\n",
      "correct: 180\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 109/300\n",
      "----------\n",
      "Epoch108 average loss:0.014625678770244122\n",
      "Epoch108 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.396\n",
      "correct: 198\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 110/300\n",
      "----------\n",
      "Epoch109 average loss:0.014817625924479216\n",
      "Epoch109 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.342\n",
      "correct: 171\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 111/300\n",
      "----------\n",
      "Epoch110 average loss:0.01503462961409241\n",
      "Epoch110 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.366\n",
      "correct: 183\n",
      "Current learning rate:  [3.90625e-08]\n",
      "\n",
      "循环 112/300\n",
      "----------\n",
      "Epoch111 average loss:0.015343804494477808\n",
      "Epoch111 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.362\n",
      "correct: 181\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 113/300\n",
      "----------\n",
      "Epoch112 average loss:0.012738115239699255\n",
      "Epoch112 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.372\n",
      "correct: 186\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 114/300\n",
      "----------\n",
      "Epoch113 average loss:0.01467007288010791\n",
      "Epoch113 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.388\n",
      "correct: 194\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 115/300\n",
      "----------\n",
      "Epoch114 average loss:0.014048460288904607\n",
      "Epoch114 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.382\n",
      "correct: 191\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 116/300\n",
      "----------\n",
      "Epoch115 average loss:0.013655377668328583\n",
      "Epoch115 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.366\n",
      "correct: 183\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 117/300\n",
      "----------\n",
      "Epoch116 average loss:0.012187189655378461\n",
      "Epoch116 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.364\n",
      "correct: 182\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 118/300\n",
      "----------\n",
      "Epoch117 average loss:0.015619729761965573\n",
      "Epoch117 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.408\n",
      "correct: 204\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 119/300\n",
      "----------\n",
      "Epoch118 average loss:0.015268677729181945\n",
      "Epoch118 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.338\n",
      "correct: 169\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 120/300\n",
      "----------\n",
      "Epoch119 average loss:0.013193506631068885\n",
      "Epoch119 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.398\n",
      "correct: 199\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 121/300\n",
      "----------\n",
      "Epoch120 average loss:0.015212203958071768\n",
      "Epoch120 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.398\n",
      "correct: 199\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 122/300\n",
      "----------\n",
      "Epoch121 average loss:0.013293607509694993\n",
      "Epoch121 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.36\n",
      "correct: 180\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 123/300\n",
      "----------\n",
      "Epoch122 average loss:0.013846517656929791\n",
      "Epoch122 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.4\n",
      "correct: 200\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 124/300\n",
      "----------\n",
      "Epoch123 average loss:0.015521868845098652\n",
      "Epoch123 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.366\n",
      "correct: 183\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 125/300\n",
      "----------\n",
      "Epoch124 average loss:0.013503992056939751\n",
      "Epoch124 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.398\n",
      "correct: 199\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 126/300\n",
      "----------\n",
      "Epoch125 average loss:0.014795591589063406\n",
      "Epoch125 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.386\n",
      "correct: 193\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 127/300\n",
      "----------\n",
      "Epoch126 average loss:0.01195921638282016\n",
      "Epoch126 finished\n",
      "---------------------------------------------------------------------------\n",
      "acc: 0.37\n",
      "correct: 185\n",
      "Current learning rate:  [1.953125e-08]\n",
      "\n",
      "循环 128/300\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     16\u001b[0m     anchor, positive, negative \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m     anchor, positive, negative \u001b[38;5;241m=\u001b[39m \u001b[43manchor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, positive\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), negative\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m     anchor_out \u001b[38;5;241m=\u001b[39m model(anchor)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/triplet_loss_experiment')\n",
    "\n",
    "\n",
    "print('Start Training')\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n循环 {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    model.train()\n",
    "    total_running_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        anchor, positive, negative = data[0]\n",
    "        anchor, positive, negative = anchor.to('cuda'), positive.to('cuda'), negative.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        anchor_out = model(anchor)\n",
    "        positive_out = model(positive)\n",
    "        negative_out = model(negative)\n",
    "        loss_val = loss(anchor_out, positive_out, negative_out)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        total_running_loss += loss_val.item()\n",
    "        running_loss += loss_val.item()\n",
    "        # writer.iteration += 1\n",
    "        if i % 10 == 9:\n",
    "            writer.add_scalar('loss', running_loss / 10, epoch * len(train_loader) + i)\n",
    "            running_loss = 0.0\n",
    "        avg_loss = total_running_loss / len(train_loader)\n",
    "        writer.add_scalar('avg_loss', avg_loss, epoch)\n",
    "    print('Epoch{} average loss:{}'.format(epoch, avg_loss))\n",
    "    print('Epoch{} finished'.format(epoch))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    ## we use acc to evaluate the model\n",
    "    with torch.no_grad():\n",
    "        # 用标签来评估模型\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        reference_embeddings_np = np.vstack([embedding.cpu().numpy() for embedding in reference_embeddings])\n",
    "        near_nn = NearestNeighbors(n_neighbors=1, algorithm='auto',metric='euclidean',).fit(reference_embeddings_np)\n",
    "        # use labels to evaluate the model\n",
    "        for i,data in enumerate(test_loader,0):\n",
    "                anchor_validation, _, _ = data[0]\n",
    "                anchor_label, _, _ = data[1]\n",
    "                batch_sizes = anchor_validation.size(0)\n",
    "                total += batch_sizes\n",
    "                anchor_validation = anchor_validation.to('cuda')\n",
    "                # print(anchor.shape)\n",
    "                anchor_out_validation = model(anchor_validation).cpu().detach().numpy()\n",
    "                # print('anchor_out_validation:', anchor_out_validation)\n",
    "                distances, indices = near_nn.kneighbors(anchor_out_validation)\n",
    "                indices = indices.reshape(-1)\n",
    "                # print('indices:', indices)\n",
    "                # print('distances:', distances)\n",
    "                for j in range(batch_sizes):\n",
    "                    # print('anchor_label:', anchor_label[j])\n",
    "                    # print('reference_labels[indices[j]]:', reference_labels[indices[j]])\n",
    "                    if reference_labels[indices[j]] == anchor_label[j]:\n",
    "                        correct += 1\n",
    "                \n",
    "        acc = correct / total\n",
    "        print('---------------------------------------------------------------------------')\n",
    "        print('acc:', acc)\n",
    "        print('correct:', correct)\n",
    "        \n",
    "        writer.add_scalar('acc', acc, epoch)\n",
    "        \n",
    "        \n",
    "        # 用scheduler来更新学习率\n",
    "        scheduler.step(acc)\n",
    "        current_lr = scheduler.get_last_lr()\n",
    "        print(\"Current learning rate: \", current_lr)\n",
    "\n",
    "        \n",
    "print('Finished Training')\n",
    "\n",
    "writer.close()\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "squeezenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
